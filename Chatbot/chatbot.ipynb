{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import random\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the Corpus of Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"C:/Users/xpert/Documents/Data_Science_Project/Chatbot/data.txt\",\"r\",errors='ignore')\n",
    "row_doc = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi, how are you doing?\ti'm fine. how about yourself?\n",
      "i'm fine. how about yourself?\ti'm pretty good. thanks for asking.\n",
      "i'm pretty good. thanks for asking.\tno problem. so how have you been?\n",
      "no problem.\n"
     ]
    }
   ],
   "source": [
    "print(row_doc[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\xpert\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\xpert\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\xpert\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df =row_doc.columns.str.lower()\n",
    "df=np.char.lower(row_doc)#converting entire text to lowercase\n",
    "nltk.download('punkt') #using the punkt tokenizer\n",
    "nltk.download('wordnet') #using the wordnet dictionary\n",
    "nltk.download('omw-1.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hi', ',', 'how', 'are', 'you']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "word_tokens = word_tokenize(row_doc)\n",
    "print(word_tokens[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hi, how are you doing?', \"i'm fine.\", 'how about yourself?', \"i'm fine.\", 'how about yourself?']\n"
     ]
    }
   ],
   "source": [
    "sentence_tokens = sent_tokenize(row_doc)\n",
    "print(sentence_tokens[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing Text-PreProcessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "def LemTokens(tokens):\n",
    "    return[lemmer.lemmatize(token) for token in tokens]\n",
    "remove_punc_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punc_dict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Greeting funtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "greet_inputs = ('hello', 'hi', 'whassup', 'how are you?')\n",
    "greet_responses = ('hi', 'Hey','Hey There!','There there!!')\n",
    "def greet(sentence):\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in greet_inputs:\n",
    "            return random.choice(greet_responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Response Generation by the Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(user_response):\n",
    "    robo1__response = ''\n",
    "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
    "    tfidf = TfidfVec.fit_transform(sentence_tokens)\n",
    "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
    "    idx = vals.argsort()[0][-2]\n",
    "    flat = vals.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-2]\n",
    "    if (req_tfidf==0):\n",
    "        robo1__response= robo1__response +\"I am sorry.Unable to understand you!\"\n",
    "        return robo1__response\n",
    "    else:\n",
    "        robo1__response = robo1__response + sentence_tokens[idx]\n",
    "        return robo1__response    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the  ChatFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I am the Retrevial Learning Bot. Start typing your text after greeting to talk to me. For ending convo type bye!\n",
      "Bot:no, please tell me.\n",
      "Bot:I am sorry.Unable to understand you!\n",
      "Bot:i know that.\n",
      "Bot:i know that.\n",
      "Bot:I am sorry.Unable to understand you!\n",
      "Bot:which school do you attend?\n",
      "Bot:I am sorry.Unable to understand you!\n",
      "Bot:what school do you go to?\n",
      "Bot:what school do you go to?\n",
      "Bot:I am sorry.Unable to understand you!\n",
      "Bot:I am sorry.Unable to understand you!\n",
      "Bot:I am sorry.Unable to understand you!\n",
      "Bot:where are you going to school?\n",
      "Bot:i go to pcc.\n",
      "Bot:are you sure?\n",
      "Bot:they sure are.\n",
      "Bot:how do you know?\n",
      "Bot:goodbye.\n"
     ]
    }
   ],
   "source": [
    "flag = True\n",
    "print(\"Hello! I am the Retrevial Learning Bot. Start typing your text after greeting to talk to me. For ending convo type bye!\")\n",
    "while(flag == True):\n",
    "    user_respose = input()\n",
    "    user_respose= user_respose.lower()\n",
    "    if(user_respose != \"bye\"):\n",
    "        if(user_respose == \"thank you\" or user_respose == \"thanks\" ):\n",
    "            flag = False\n",
    "            print(\"Bot: you are wellcom..\")\n",
    "        else:\n",
    "            if(greet(user_respose)!= None):\n",
    "                print('Bot' + greet(user_respose))\n",
    "            else:\n",
    "                sentence_tokens.append(user_respose)\n",
    "                word_tokens = word_tokens + nltk.word_tokenize(user_respose)\n",
    "                final_words = list(set(word_tokens))\n",
    "                print('Bot:', end = '')\n",
    "                print(response(user_respose))\n",
    "                sentence_tokens.remove(user_respose)\n",
    "    else:\n",
    "        flag = False\n",
    "        print(\"Bot: Goodbye!\")                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
